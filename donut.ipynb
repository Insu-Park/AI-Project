'''

인공지능 

Multi-Layer perceptron 구현

서울시립대학교 컴퓨터과학부 2014920017 박인수

도넛 구현

'''

import tensorflow as tf
import numpy as np
from numpy import *
from numpy.random import multivariate_normal
import matplotlib.pyplot as plt
import pandas as pd
from pandas import Series, DataFrame

# Hidden Layer 노드 개수
num_units = 16

x = tf.placeholder(tf.float32, [None, 2])
w1 = tf.Variable(tf.truncated_normal([2, num_units]))
b1 = tf.Variable(tf.zeros([num_units]))
hidden1 = tf.nn.sigmoid(tf.matmul(x,w1) + b1)
w0 =  tf.Variable(tf.zeros([num_units, 1]))
b0 = tf.Variable(tf.zeros([1]))
p = tf.nn.sigmoid(tf.matmul(hidden1, w0) + b0)
y = tf.placeholder(tf.float32, [None, 1])
loss = tf.reduce_sum(tf.square(y-p))
train_step = tf.train.MomentumOptimizer(0.05, 0.05).minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

# 트레이닝 데이터
train_set_x = [[0.,0.], [0.,1.], [1.,0.], [1.,1.], [0.5,1.], [1.,0.5], [0.,0.5], [0.5,0.], [0.5,0.5]] 
train_set_y = [0,0,0,0,0,0,0,0,1]
train_x = np.zeros([9,2])
train_y = np.zeros([9,1])

for row in range(0,9):
  for col in range(0,2):
    train_x[row][col] = train_set_x[row][col]
for row in range(0,9):
    train_y[row] = train_set_y[row]   
    
# Iteration Graph 세팅
fig1 = plt.figure(figsize=(8,8))
iter_subplot = fig1.add_subplot(1, 1, 1)

# Learning Graph 세팅
fig = [0, 0, 0, 0, 0, 0, 0, 0]
subplot = [0, 0, 0, 0, 0, 0, 0, 0]
for i in range(0,8):
  fig[i] = plt.figure(figsize=(8,8))
  subplot[i] = fig[i].add_subplot(1, 1, 1)
  subplot[i].set_xlim(-0.5, 1.5)
  subplot[i].set_ylim(-0.5, 1.5)

# 그래프 그리기
locations = []
for x2 in np.linspace(-0.5, 1.5, 100):
  for x1 in np.linspace(-0.5, 1.5, 100):
    locations.append((x1,x2))
    
i, count = 0, 0
loss_valarr = []

for _ in range(40000):
  i+= 1
  sess.run(train_step, feed_dict={x:train_x, y:train_y})
  loss_val = sess.run(loss, feed_dict={x:train_x, y:train_y})
  loss_valarr.append(loss_val)
  # 500번 실행할 때마다 그래프에 표시
  if i % 5000 == 0:
    count += 1
    print('Step: %d, Loss: %f' %(i, loss_val))
    p_vals = sess.run(p, feed_dict={x:locations})
    p_vals = p_vals.reshape((100,100))
    count = int(i/5000)-1
    subplot[count].imshow(p_vals, origin='lower', extent=(-1,2,-1,2), cmap=plt.cm.gray_r, alpha=0.5)
    subplot[count].scatter(train_set1.x1, train_set1.x2, marker='o')
    subplot[count].scatter(train_set0.x1, train_set0.x2, marker='x')
    
# loss 배열을  그래프로 표시
iter_subplot.plot(range(len(loss_valarr)), loss_valarr,linewidth=2, label='Error')
iter_subplot.legend(loc='upper left')

# X1, X2 좌표에 대해 데이터를 점으로 표시
train_set = hstack((train_x, train_y))
df = DataFrame(train_set)
df.columns = ["x1", "x2", "y"]          
train_set0 = df[df['y']==0]
train_set1 = df[df['y']==1] 

# w를 파일로 저장
w0_val, b0_val, w1_val, b1_val = sess.run([w0, b0, w1, b1])
w01_val, w02_val = w0_val[0][0], w0_val[1][0]
w11_val, w12_val, w13_val, w14_val = w1_val[0][0], w1_val[1][0], w1_val[0][1], w1_val[1][1]
b11_val, b12_val = b1_val[0], b1_val[1]
w_set = vstack((w11_val, w12_val, w13_val, w14_val, b11_val, b12_val, w01_val, w02_val, b0_val))
w_set.tofile('test.txt', sep = '\t')
